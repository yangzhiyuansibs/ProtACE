{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/po/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from time import sleep\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "from torch.utils.data import Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 读取训练集和测试集 CSV 文件\n",
    "train_csv_file_path = '/root/ACE/pca_train.csv'  # 替换为实际的训练集 CSV 文件路径\n",
    "test_csv_file_path = '/root/ACE/pca_test.csv'    # 替换为实际的测试集 CSV 文件路径\n",
    "\n",
    "train_data = pd.read_csv(train_csv_file_path)\n",
    "test_data = pd.read_csv(test_csv_file_path)\n",
    "\n",
    "# 假设第一列是标签，后面的列都是特征\n",
    "train_labels = train_data.iloc[:, 0]  # 训练集标签\n",
    "train_embeddings = train_data.iloc[:, 1:]  # 训练集特征\n",
    "\n",
    "test_labels = test_data.iloc[:, 0]  # 测试集标签\n",
    "test_embeddings = test_data.iloc[:, 1:]  # 测试集特征\n",
    "\n",
    "# 自定义 Dataset 类\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        embedding = torch.tensor(self.embeddings.iloc[idx].values, dtype=torch.float32)  # 转换为 torch 张量\n",
    "        label = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "        return embedding, label\n",
    "\n",
    "# 创建训练和测试数据集\n",
    "train_dataset = CustomDataset(train_embeddings, train_labels)\n",
    "test_dataset = CustomDataset(test_embeddings, test_labels)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# 忽略所有警告\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import h5py\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, lstm_out):\n",
    "        out = self.linear(lstm_out)\n",
    "        score = torch.bmm(out, out.transpose(1, 2))\n",
    "        attn = self.softmax(score)\n",
    "        context = torch.bmm(attn, lstm_out)\n",
    "        return context\n",
    "    \n",
    "    \n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, drop):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.attention = Attention(input_size)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        # 批归一化层\n",
    "        self.batch_norm1 = nn.BatchNorm1d(512)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(32)\n",
    "\n",
    "        # 全连接层\n",
    "        self.fc2 = nn.Linear(128, 512)\n",
    "        self.fc3 = nn.Linear(512, 32)\n",
    "        self.fc = nn.Linear(32, 2)\n",
    "    def forward(self, x):\n",
    "        out = self.attention(x)\n",
    "        out, _ = self.lstm(out)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        out = self.batch_norm(out)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        # 全连接层操作\n",
    "        out = self.fc2(out)\n",
    "        # 批归一化层\n",
    "        out = out.permute(0, 2, 1)  # 调整维度以适应 BatchNorm1d 的输入\n",
    "        out = self.batch_norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = out.permute(0, 2, 1)  # 恢复原始的维度顺序\n",
    "\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc3(out)\n",
    "        out = out.permute(0, 2, 1)  # 调整维度以适应 BatchNorm1d 的输入\n",
    "        out = self.batch_norm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = out.permute(0, 2, 1)  # 恢复原始的维度顺序\n",
    "\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# class CNNModel(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers, num_classes, drop):\n",
    "#         super(CNNModel, self).__init__()\n",
    "#         self.relu = nn.ReLU(True)\n",
    "#         self.dropout = nn.Dropout(drop)\n",
    "        \n",
    "#         # Convolutional layers\n",
    "#         self.conv1 = nn.Conv1d(input_size, 512, kernel_size=3, padding=1)\n",
    "#         self.batch_norm1 = nn.BatchNorm1d(512)\n",
    "        \n",
    "#         self.conv2 = nn.Conv1d(512, 256, kernel_size=3, padding=1)\n",
    "#         self.batch_norm2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "#         self.conv3 = nn.Conv1d(256, 128, kernel_size=3, padding=1)\n",
    "#         self.batch_norm3 = nn.BatchNorm1d(128)\n",
    "        \n",
    "#         self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "#         # Attention layer (ensure Attention class is defined)\n",
    "#         self.attention = Attention(128)\n",
    "        \n",
    "#         # Fully connected layers\n",
    "#         self.fc1 = nn.Linear(128, 256)\n",
    "#         self.batch_norm_fc1 = nn.BatchNorm1d(256)\n",
    "        \n",
    "#         self.fc2 = nn.Linear(256, 32)\n",
    "#         self.batch_norm_fc2 = nn.BatchNorm1d(32)\n",
    "        \n",
    "#         self.fc_final = nn.Linear(32, num_classes)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # x shape: [batch_size, seq_length, input_size]\n",
    "#         out = x.permute(0, 2, 1)  # [batch_size, input_size, seq_length]\n",
    "        \n",
    "#         # First convolutional layer\n",
    "#         out = self.conv1(out)\n",
    "#         out = self.batch_norm1(out)\n",
    "#         out = self.relu(out)\n",
    "        \n",
    "#         # Second convolutional layer\n",
    "#         out = self.conv2(out)\n",
    "#         out = self.batch_norm2(out)\n",
    "#         out = self.relu(out)\n",
    "        \n",
    "#         # Third convolutional layer\n",
    "#         out = self.conv3(out)\n",
    "#         out = self.batch_norm3(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.maxpool(out)\n",
    "        \n",
    "#         out = out.permute(0, 2, 1)  # [batch_size, seq_length, features]\n",
    "        \n",
    "#         # Attention layer\n",
    "#         out = self.attention(out)\n",
    "        \n",
    "#         # Global average pooling\n",
    "#         out = out.mean(dim=1)  # [batch_size, features]\n",
    "        \n",
    "#         # Fully connected layers\n",
    "#         out = self.fc1(out)\n",
    "#         out = self.batch_norm_fc1(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.dropout(out)\n",
    "        \n",
    "#         out = self.fc2(out)\n",
    "#         out = self.batch_norm_fc2(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.dropout(out)\n",
    "        \n",
    "#         out = self.fc_final(out)\n",
    "#         return out\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, drop):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(input_size, 128, kernel_size=3, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(128, 64, kernel_size=3, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(32)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Attention layer (ensure Attention class is defined)\n",
    "        self.attention = Attention(32)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32, 64)\n",
    "        self.batch_norm_fc1 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "        self.batch_norm_fc2 = nn.BatchNorm1d(16)\n",
    "        \n",
    "        self.fc_final = nn.Linear(16, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_length, input_size]\n",
    "        out = x.permute(0, 2, 1)  # [batch_size, input_size, seq_length]\n",
    "        \n",
    "        # First convolutional layer\n",
    "        out = self.conv1(out)\n",
    "        out = self.batch_norm1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        out = self.conv2(out)\n",
    "        out = self.batch_norm2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        # Third convolutional layer\n",
    "        out = self.conv3(out)\n",
    "        out = self.batch_norm3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        \n",
    "        out = out.permute(0, 2, 1)  # [batch_size, seq_length, features]\n",
    "        \n",
    "        # Attention layer\n",
    "        out = self.attention(out)\n",
    "        \n",
    "        # Global average pooling\n",
    "        out = out.mean(dim=1)  # [batch_size, features]\n",
    "        \n",
    "        # Fully connected layers\n",
    "        out = self.fc1(out)\n",
    "        out = self.batch_norm_fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        out = self.batch_norm_fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc_final(out)\n",
    "        return out\n",
    "class DualModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size_cnn, hidden_size_lstm, num_layers_cnn, num_layers_lstm, num_classes, drop_cnn, drop_lstm):\n",
    "        super(DualModel, self).__init__()\n",
    "        self.cnn = CNNModel(input_size, hidden_size_cnn, num_layers_cnn, num_classes, drop_cnn)\n",
    "        self.lstm = LSTMModel(input_size, hidden_size_lstm, num_layers_lstm, num_classes, drop_lstm)\n",
    "        self.weight = nn.Parameter(torch.tensor(0.7))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_cnn = self.cnn(x)\n",
    "        #out_lstm = self.lstm(x)\n",
    "        #out = self.weight * out_cnn + (1 - self.weight) * out_lstm\n",
    "        return out_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义多层感知机（MLP）模型\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout for regularization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-11 20:12:15,239] A new study created in memory with name: no-name-b89351e8-eb2f-4942-9194-f4579ec8e13b\n",
      "[I 2024-10-11 20:12:15,246] Trial 0 finished with value: 0.9113924050632911 and parameters: {'C': 0.06711512209020946, 'solver': 'liblinear', 'max_iter': 951}. Best is trial 0 with value: 0.9113924050632911.\n",
      "[I 2024-10-11 20:12:15,251] Trial 1 finished with value: 0.9113924050632911 and parameters: {'C': 0.05929412122396233, 'solver': 'liblinear', 'max_iter': 825}. Best is trial 0 with value: 0.9113924050632911.\n",
      "[I 2024-10-11 20:12:15,258] Trial 2 finished with value: 0.9113924050632911 and parameters: {'C': 9.495743123274119, 'solver': 'lbfgs', 'max_iter': 925}. Best is trial 0 with value: 0.9113924050632911.\n",
      "[I 2024-10-11 20:12:15,266] Trial 3 finished with value: 0.9113924050632911 and parameters: {'C': 13.621477763911821, 'solver': 'lbfgs', 'max_iter': 752}. Best is trial 0 with value: 0.9113924050632911.\n",
      "[I 2024-10-11 20:12:15,276] Trial 4 finished with value: 0.9113924050632911 and parameters: {'C': 27.753905622132777, 'solver': 'lbfgs', 'max_iter': 731}. Best is trial 0 with value: 0.9113924050632911.\n",
      "[I 2024-10-11 20:12:15,285] Trial 5 finished with value: 0.8987341772151899 and parameters: {'C': 1.482184386083047, 'solver': 'lbfgs', 'max_iter': 368}. Best is trial 0 with value: 0.9113924050632911.\n",
      "[I 2024-10-11 20:12:15,294] Trial 6 finished with value: 0.9113924050632911 and parameters: {'C': 0.011048331406724851, 'solver': 'lbfgs', 'max_iter': 974}. Best is trial 0 with value: 0.9113924050632911.\n",
      "[I 2024-10-11 20:12:15,306] Trial 7 finished with value: 0.9113924050632911 and parameters: {'C': 46.991173060747734, 'solver': 'liblinear', 'max_iter': 559}. Best is trial 0 with value: 0.9113924050632911.\n",
      "[I 2024-10-11 20:12:15,313] Trial 8 finished with value: 0.9113924050632911 and parameters: {'C': 1.9661830126502688, 'solver': 'liblinear', 'max_iter': 770}. Best is trial 0 with value: 0.9113924050632911.\n",
      "[I 2024-10-11 20:12:15,320] Trial 9 finished with value: 0.9113924050632911 and parameters: {'C': 0.33514212895230927, 'solver': 'liblinear', 'max_iter': 380}. Best is trial 0 with value: 0.9113924050632911.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy (BAcc): 0.9020, Sensitivity (Sn): 0.8800, Specificity (Sp): 0.9241, MCC: 0.7908, AUROC: 0.9434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-11 20:12:15,342] Trial 10 finished with value: 0.9240506329113924 and parameters: {'C': 0.001072670638035624, 'solver': 'liblinear', 'max_iter': 100}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,358] Trial 11 finished with value: 0.9240506329113924 and parameters: {'C': 0.0013584047732548591, 'solver': 'liblinear', 'max_iter': 147}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,373] Trial 12 finished with value: 0.9240506329113924 and parameters: {'C': 0.001111774726122675, 'solver': 'liblinear', 'max_iter': 107}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,391] Trial 13 finished with value: 0.9240506329113924 and parameters: {'C': 0.0010367939980779034, 'solver': 'liblinear', 'max_iter': 131}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,411] Trial 14 finished with value: 0.9240506329113924 and parameters: {'C': 0.006248629757705615, 'solver': 'liblinear', 'max_iter': 300}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,427] Trial 15 finished with value: 0.9240506329113924 and parameters: {'C': 0.005869956276750058, 'solver': 'liblinear', 'max_iter': 238}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,442] Trial 16 finished with value: 0.9113924050632911 and parameters: {'C': 0.028599306955502946, 'solver': 'liblinear', 'max_iter': 502}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,458] Trial 17 finished with value: 0.9240506329113924 and parameters: {'C': 0.002653862591171132, 'solver': 'liblinear', 'max_iter': 209}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,475] Trial 18 finished with value: 0.9113924050632911 and parameters: {'C': 0.26831145607360807, 'solver': 'liblinear', 'max_iter': 505}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,491] Trial 19 finished with value: 0.9113924050632911 and parameters: {'C': 0.017750336745139945, 'solver': 'liblinear', 'max_iter': 203}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,507] Trial 20 finished with value: 0.9240506329113924 and parameters: {'C': 0.0037314250213159664, 'solver': 'liblinear', 'max_iter': 380}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,523] Trial 21 finished with value: 0.9240506329113924 and parameters: {'C': 0.0010353599231276481, 'solver': 'liblinear', 'max_iter': 106}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,541] Trial 22 finished with value: 0.9240506329113924 and parameters: {'C': 0.001781780944573068, 'solver': 'liblinear', 'max_iter': 124}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,557] Trial 23 finished with value: 0.9240506329113924 and parameters: {'C': 0.0041284993149134286, 'solver': 'liblinear', 'max_iter': 289}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,573] Trial 24 finished with value: 0.9240506329113924 and parameters: {'C': 0.0020157250015681158, 'solver': 'liblinear', 'max_iter': 168}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,592] Trial 25 finished with value: 0.9240506329113924 and parameters: {'C': 0.008114785307331427, 'solver': 'liblinear', 'max_iter': 296}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,611] Trial 26 finished with value: 0.9113924050632911 and parameters: {'C': 0.04529477557466049, 'solver': 'lbfgs', 'max_iter': 616}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,628] Trial 27 finished with value: 0.9113924050632911 and parameters: {'C': 0.13296948084207064, 'solver': 'liblinear', 'max_iter': 256}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,645] Trial 28 finished with value: 0.9240506329113924 and parameters: {'C': 0.0010246760264060544, 'solver': 'liblinear', 'max_iter': 104}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,662] Trial 29 finished with value: 0.9113924050632911 and parameters: {'C': 0.015905360909630104, 'solver': 'liblinear', 'max_iter': 184}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,680] Trial 30 finished with value: 0.9240506329113924 and parameters: {'C': 0.0025692993690190845, 'solver': 'liblinear', 'max_iter': 427}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,698] Trial 31 finished with value: 0.9240506329113924 and parameters: {'C': 0.0012599778694358105, 'solver': 'liblinear', 'max_iter': 151}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,716] Trial 32 finished with value: 0.9240506329113924 and parameters: {'C': 0.0034280920009760038, 'solver': 'liblinear', 'max_iter': 159}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,733] Trial 33 finished with value: 0.9240506329113924 and parameters: {'C': 0.0010043139387756821, 'solver': 'liblinear', 'max_iter': 104}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,750] Trial 34 finished with value: 0.9240506329113924 and parameters: {'C': 0.0022209802436578396, 'solver': 'liblinear', 'max_iter': 244}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,769] Trial 35 finished with value: 0.9113924050632911 and parameters: {'C': 0.010433820685274715, 'solver': 'lbfgs', 'max_iter': 333}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,788] Trial 36 finished with value: 0.9240506329113924 and parameters: {'C': 0.0051916611311128265, 'solver': 'liblinear', 'max_iter': 210}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,810] Trial 37 finished with value: 0.8987341772151899 and parameters: {'C': 3.7200398046345233, 'solver': 'lbfgs', 'max_iter': 858}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,828] Trial 38 finished with value: 0.9113924050632911 and parameters: {'C': 0.09384631549193188, 'solver': 'liblinear', 'max_iter': 673}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,847] Trial 39 finished with value: 0.9113924050632911 and parameters: {'C': 0.0248782301367914, 'solver': 'lbfgs', 'max_iter': 153}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,867] Trial 40 finished with value: 0.9113924050632911 and parameters: {'C': 0.7393181899690003, 'solver': 'liblinear', 'max_iter': 433}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,891] Trial 41 finished with value: 0.9240506329113924 and parameters: {'C': 0.005489144045983403, 'solver': 'liblinear', 'max_iter': 287}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,911] Trial 42 finished with value: 0.9240506329113924 and parameters: {'C': 0.0017071381224883877, 'solver': 'liblinear', 'max_iter': 144}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,931] Trial 43 finished with value: 0.9240506329113924 and parameters: {'C': 0.0017103592007796213, 'solver': 'liblinear', 'max_iter': 333}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,948] Trial 44 finished with value: 0.9240506329113924 and parameters: {'C': 0.00803752550218995, 'solver': 'liblinear', 'max_iter': 216}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,966] Trial 45 finished with value: 0.9240506329113924 and parameters: {'C': 0.003003494692314695, 'solver': 'liblinear', 'max_iter': 184}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:15,984] Trial 46 finished with value: 0.9240506329113924 and parameters: {'C': 0.00495638421601165, 'solver': 'liblinear', 'max_iter': 259}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:16,006] Trial 47 finished with value: 0.8987341772151899 and parameters: {'C': 0.0016220872795275774, 'solver': 'lbfgs', 'max_iter': 328}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:16,024] Trial 48 finished with value: 0.9240506329113924 and parameters: {'C': 0.013258440710429092, 'solver': 'liblinear', 'max_iter': 121}. Best is trial 10 with value: 0.9240506329113924.\n",
      "[I 2024-10-11 20:12:16,041] Trial 49 finished with value: 0.9240506329113924 and parameters: {'C': 0.007226879622680599, 'solver': 'liblinear', 'max_iter': 226}. Best is trial 10 with value: 0.9240506329113924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy (BAcc): 0.9060, Sensitivity (Sn): 0.8880, Specificity (Sp): 0.9241, MCC: 0.7998, AUROC: 0.9477\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score, balanced_accuracy_score, recall_score\n",
    "import optuna\n",
    "\n",
    "# 加载保存的模型\n",
    "svm_model = joblib.load('/root/ACE/model/best_svm_model.pkl')\n",
    "rl_model = joblib.load('/root/ACE/model/best_logistic_regression_model.pkl')\n",
    "\n",
    "# 读取训练集和测试集 CSV 文件\n",
    "train_csv_file_path = '/root/ACE/pca_train.csv'  # 替换为实际的训练集 CSV 文件路径\n",
    "test_csv_file_path = '/root/ACE/pca_test.csv'    # 替换为实际的测试集 CSV 文件路径\n",
    "\n",
    "train_data = pd.read_csv(train_csv_file_path)\n",
    "test_data = pd.read_csv(test_csv_file_path)\n",
    "\n",
    "# 假设第一列是标签，后面的列都是特征\n",
    "train_labels = train_data.iloc[:, 0]  # 训练集标签\n",
    "train_embeddings = train_data.iloc[:, 1:]  # 训练集特征\n",
    "\n",
    "test_labels = test_data.iloc[:, 0]  # 测试集标签\n",
    "test_embeddings = test_data.iloc[:, 1:]  # 测试集特征\n",
    "\n",
    "# 自定义 Dataset 类\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        embedding = torch.tensor(self.embeddings.iloc[idx].values, dtype=torch.float32)  # 转换为 torch 张量\n",
    "        label = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "        return embedding, label\n",
    "\n",
    "# 创建训练和测试数据集\n",
    "train_dataset = CustomDataset(train_embeddings, train_labels)\n",
    "test_dataset = CustomDataset(test_embeddings, test_labels)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# 加载 CNN 模型\n",
    "model = torch.load('/root/ACE/model/best_model_trial_cnn.pth')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 使用 CNN 模型对测试集进行预测\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        data = data.to(device).unsqueeze(1)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(data)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        all_preds.append(probs[:, 1].cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "binary_preds = (all_preds > 0.5).astype(int)\n",
    "\n",
    "# 计算评估指标\n",
    "conf_matrix = confusion_matrix(all_labels, binary_preds)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "auc = roc_auc_score(all_labels, all_preds)\n",
    "balanced_acc = balanced_accuracy_score(all_labels, binary_preds)\n",
    "sensitivity = recall_score(all_labels, binary_preds)\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "mcc = matthews_corrcoef(all_labels, binary_preds)\n",
    "\n",
    "# 打印评估指标\n",
    "print(f'Balanced Accuracy (BAcc): {balanced_acc:.4f}, Sensitivity (Sn): {sensitivity:.4f}, '\n",
    "      f'Specificity (Sp): {specificity:.4f}, MCC: {mcc:.4f}, AUROC: {auc:.4f}')\n",
    "\n",
    "# 使用每个基模型对训练集和测试集进行预测\n",
    "cnn_train_pred = model(torch.tensor(train_embeddings.values, dtype=torch.float32).to(device).unsqueeze(1)).detach().cpu().numpy()[:, 1]  # 使用 CNN 模型的预测结果\n",
    "svm_train_pred = svm_model.predict(train_embeddings)\n",
    "rl_train_pred = rl_model.predict(train_embeddings)\n",
    "\n",
    "cnn_test_pred = model(torch.tensor(test_embeddings.values, dtype=torch.float32).to(device).unsqueeze(1)).detach().cpu().numpy()[:, 1]  # 使用 CNN 模型的预测结果\n",
    "svm_test_pred = svm_model.predict(test_embeddings)\n",
    "rl_test_pred = rl_model.predict(test_embeddings)\n",
    "\n",
    "# 确保所有预测结果具有相同长度\n",
    "cnn_train_pred = cnn_train_pred[:len(train_labels)]\n",
    "svm_train_pred = svm_train_pred[:len(train_labels)]\n",
    "rl_train_pred = rl_train_pred[:len(train_labels)]\n",
    "\n",
    "cnn_test_pred = cnn_test_pred[:len(test_labels)]\n",
    "svm_test_pred = svm_test_pred[:len(test_labels)]\n",
    "rl_test_pred = rl_test_pred[:len(test_labels)]\n",
    "\n",
    "# 将每个模型的预测结果作为新的特征\n",
    "stacked_train_features = np.vstack((cnn_train_pred, svm_train_pred, rl_train_pred)).T\n",
    "stacked_test_features = np.vstack((cnn_test_pred, svm_test_pred, rl_test_pred)).T\n",
    "\n",
    "# 使用逻辑回归进行堆叠并进行调参\n",
    "\n",
    "def objective(trial):\n",
    "    C = trial.suggest_loguniform('C', 1e-3, 1e2)\n",
    "    solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear'])\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 1000)\n",
    "    \n",
    "    stacking_model = LogisticRegression(C=C, solver=solver, max_iter=max_iter)\n",
    "    stacking_model.fit(stacked_train_features, train_labels)\n",
    "    stacked_binary_preds = stacking_model.predict(stacked_test_features)\n",
    "    conf_matrix = confusion_matrix(test_labels, stacked_binary_preds)\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    return specificity\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params = study.best_params\n",
    "stacking_model = LogisticRegression(**best_params)\n",
    "stacking_model.fit(stacked_train_features, train_labels)\n",
    "\n",
    "# 对测试集进行预测\n",
    "stacked_pred = stacking_model.predict_proba(stacked_test_features)[:, 1]\n",
    "\n",
    "# 将预测结果转换为二分类（例如，0.5 为阈值）\n",
    "stacked_binary_preds = (stacked_pred > 0.5).astype(int)\n",
    "\n",
    "# 计算评估指标\n",
    "conf_matrix = confusion_matrix(test_labels, stacked_binary_preds)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "auc = roc_auc_score(test_labels, stacked_pred)\n",
    "balanced_acc = balanced_accuracy_score(test_labels, stacked_binary_preds)\n",
    "sensitivity = recall_score(test_labels, stacked_binary_preds)\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "mcc = matthews_corrcoef(test_labels, stacked_binary_preds)\n",
    "\n",
    "# 打印评估指标\n",
    "print(f'Balanced Accuracy (BAcc): {balanced_acc:.4f}, Sensitivity (Sn): {sensitivity:.4f}, '\n",
    "      f'Specificity (Sp): {specificity:.4f}, MCC: {mcc:.4f}, AUROC: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy (BAcc): 0.9020, Sensitivity (Sn): 0.8800, Specificity (Sp): 0.9241, MCC: 0.7908, AUROC: 0.9434\n",
      "Balanced Accuracy (BAcc): 0.9174, Sensitivity (Sn): 0.9360, Specificity (Sp): 0.8987, MCC: 0.8347, AUROC: 0.9477\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score, balanced_accuracy_score, recall_score\n",
    "import optuna\n",
    "\n",
    "# 加载保存的模型\n",
    "svm_model = joblib.load('/root/ACE/model/best_svm_model.pkl')\n",
    "rl_model = joblib.load('/root/ACE/model/best_logistic_regression_model.pkl')\n",
    "\n",
    "# 读取训练集和测试集 CSV 文件\n",
    "train_csv_file_path = '/root/ACE/pca_train.csv'  # 替换为实际的训练集 CSV 文件路径\n",
    "test_csv_file_path = '/root/ACE/pca_test.csv'    # 替换为实际的测试集 CSV 文件路径\n",
    "\n",
    "train_data = pd.read_csv(train_csv_file_path)\n",
    "test_data = pd.read_csv(test_csv_file_path)\n",
    "\n",
    "# 假设第一列是标签，后面的列都是特征\n",
    "train_labels = train_data.iloc[:, 0]  # 训练集标签\n",
    "train_embeddings = train_data.iloc[:, 1:]  # 训练集特征\n",
    "\n",
    "test_labels = test_data.iloc[:, 0]  # 测试集标签\n",
    "test_embeddings = test_data.iloc[:, 1:]  # 测试集特征\n",
    "\n",
    "# 自定义 Dataset 类\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        embedding = torch.tensor(self.embeddings.iloc[idx].values, dtype=torch.float32)  # 转换为 torch 张量\n",
    "        label = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "        return embedding, label\n",
    "\n",
    "# 创建训练和测试数据集\n",
    "train_dataset = CustomDataset(train_embeddings, train_labels)\n",
    "test_dataset = CustomDataset(test_embeddings, test_labels)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# 加载 CNN 模型\n",
    "model = torch.load('/root/ACE/model/best_model_trial_cnn.pth')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 使用 CNN 模型对测试集进行预测\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        data = data.to(device).unsqueeze(1)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(data)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        all_preds.append(probs[:, 1].cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "binary_preds = (all_preds > 0.5).astype(int)\n",
    "\n",
    "# 计算评估指标\n",
    "conf_matrix = confusion_matrix(all_labels, binary_preds)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "auc = roc_auc_score(all_labels, all_preds)\n",
    "balanced_acc = balanced_accuracy_score(all_labels, binary_preds)\n",
    "sensitivity = recall_score(all_labels, binary_preds)\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "mcc = matthews_corrcoef(all_labels, binary_preds)\n",
    "\n",
    "# 打印评估指标\n",
    "print(f'Balanced Accuracy (BAcc): {balanced_acc:.4f}, Sensitivity (Sn): {sensitivity:.4f}, '\n",
    "      f'Specificity (Sp): {specificity:.4f}, MCC: {mcc:.4f}, AUROC: {auc:.4f}')\n",
    "\n",
    "# 使用每个基模型对训练集和测试集进行预测\n",
    "cnn_train_pred = model(torch.tensor(train_embeddings.values, dtype=torch.float32).to(device).unsqueeze(1)).detach().cpu().numpy()[:, 1]  # 使用 CNN 模型的预测结果\n",
    "svm_train_pred = svm_model.predict(train_embeddings)\n",
    "rl_train_pred = rl_model.predict(train_embeddings)\n",
    "\n",
    "cnn_test_pred = model(torch.tensor(test_embeddings.values, dtype=torch.float32).to(device).unsqueeze(1)).detach().cpu().numpy()[:, 1]  # 使用 CNN 模型的预测结果\n",
    "svm_test_pred = svm_model.predict(test_embeddings)\n",
    "rl_test_pred = rl_model.predict(test_embeddings)\n",
    "\n",
    "# 确保所有预测结果具有相同长度\n",
    "cnn_train_pred = cnn_train_pred[:len(train_labels)]\n",
    "svm_train_pred = svm_train_pred[:len(train_labels)]\n",
    "rl_train_pred = rl_train_pred[:len(train_labels)]\n",
    "\n",
    "cnn_test_pred = cnn_test_pred[:len(test_labels)]\n",
    "svm_test_pred = svm_test_pred[:len(test_labels)]\n",
    "rl_test_pred = rl_test_pred[:len(test_labels)]\n",
    "\n",
    "# 创建 VotingClassifier 模型\n",
    "voting_model = VotingClassifier(estimators=[\n",
    "    ('svm', svm_model),\n",
    "    ('rl', rl_model),\n",
    "    ('cnn', LogisticRegression().fit(stacked_train_features, train_labels))  # 使用 CNN 特征训练逻辑回归\n",
    "], voting='soft')\n",
    "\n",
    "# 训练 VotingClassifier\n",
    "voting_model.fit(stacked_train_features, train_labels)\n",
    "\n",
    "# 对测试集进行预测\n",
    "stacked_pred = voting_model.predict_proba(stacked_test_features)[:, 1]\n",
    "\n",
    "# 将预测结果转换为二分类（例如，0.5 为阈值）\n",
    "stacked_binary_preds = (stacked_pred > 0.5).astype(int)\n",
    "\n",
    "# 计算评估指标\n",
    "conf_matrix = confusion_matrix(test_labels, stacked_binary_preds)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "auc = roc_auc_score(test_labels, stacked_pred)\n",
    "balanced_acc = balanced_accuracy_score(test_labels, stacked_binary_preds)\n",
    "sensitivity = recall_score(test_labels, stacked_binary_preds)\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "mcc = matthews_corrcoef(test_labels, stacked_binary_preds)\n",
    "\n",
    "# 打印评估指标\n",
    "print(f'Balanced Accuracy (BAcc): {balanced_acc:.4f}, Sensitivity (Sn): {sensitivity:.4f}, '\n",
    "      f'Specificity (Sp): {specificity:.4f}, MCC: {mcc:.4f}, AUROC: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy (BAcc): 0.9020, Sensitivity (Sn): 0.8800, Specificity (Sp): 0.9241, MCC: 0.7908, AUROC: 0.9434\n",
      "Balanced Accuracy (BAcc): 0.9174, Sensitivity (Sn): 0.9360, Specificity (Sp): 0.8987, MCC: 0.8347, AUROC: 0.9476\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score, balanced_accuracy_score, recall_score\n",
    "import optuna\n",
    "\n",
    "# 加载保存的模型\n",
    "svm_model = joblib.load('/root/ACE/model/best_svm_model.pkl')\n",
    "rl_model = joblib.load('/root/ACE/model/best_logistic_regression_model.pkl')\n",
    "\n",
    "# 读取训练集和测试集 CSV 文件\n",
    "train_csv_file_path = '/root/ACE/pca_train.csv'  # 替换为实际的训练集 CSV 文件路径\n",
    "test_csv_file_path = '/root/ACE/pca_test.csv'    # 替换为实际的测试集 CSV 文件路径\n",
    "\n",
    "train_data = pd.read_csv(train_csv_file_path)\n",
    "test_data = pd.read_csv(test_csv_file_path)\n",
    "\n",
    "# 假设第一列是标签，后面的列都是特征\n",
    "train_labels = train_data.iloc[:, 0]  # 训练集标签\n",
    "train_embeddings = train_data.iloc[:, 1:]  # 训练集特征\n",
    "\n",
    "test_labels = test_data.iloc[:, 0]  # 测试集标签\n",
    "test_embeddings = test_data.iloc[:, 1:]  # 测试集特征\n",
    "\n",
    "# 自定义 Dataset 类\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        embedding = torch.tensor(self.embeddings.iloc[idx].values, dtype=torch.float32)  # 转换为 torch 张量\n",
    "        label = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "        return embedding, label\n",
    "\n",
    "# 创建训练和测试数据集\n",
    "train_dataset = CustomDataset(train_embeddings, train_labels)\n",
    "test_dataset = CustomDataset(test_embeddings, test_labels)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# 加载 CNN 模型\n",
    "model = torch.load('/root/ACE/model/best_model_trial_cnn.pth')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 使用 CNN 模型对测试集进行预测\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        data = data.to(device).unsqueeze(1)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(data)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        all_preds.append(probs[:, 1].cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "binary_preds = (all_preds > 0.5).astype(int)\n",
    "\n",
    "# 计算评估指标\n",
    "conf_matrix = confusion_matrix(all_labels, binary_preds)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "auc = roc_auc_score(all_labels, all_preds)\n",
    "balanced_acc = balanced_accuracy_score(all_labels, binary_preds)\n",
    "sensitivity = recall_score(all_labels, binary_preds)\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "mcc = matthews_corrcoef(all_labels, binary_preds)\n",
    "\n",
    "# 打印评估指标\n",
    "print(f'Balanced Accuracy (BAcc): {balanced_acc:.4f}, Sensitivity (Sn): {sensitivity:.4f}, '\n",
    "      f'Specificity (Sp): {specificity:.4f}, MCC: {mcc:.4f}, AUROC: {auc:.4f}')\n",
    "\n",
    "# 使用每个基模型对训练集和测试集进行预测\n",
    "cnn_train_pred = model(torch.tensor(train_embeddings.values, dtype=torch.float32).to(device).unsqueeze(1)).detach().cpu().numpy()[:, 1]  # 使用 CNN 模型的预测结果\n",
    "svm_train_pred = svm_model.predict(train_embeddings)\n",
    "rl_train_pred = rl_model.predict(train_embeddings)\n",
    "\n",
    "cnn_test_pred = model(torch.tensor(test_embeddings.values, dtype=torch.float32).to(device).unsqueeze(1)).detach().cpu().numpy()[:, 1]  # 使用 CNN 模型的预测结果\n",
    "svm_test_pred = svm_model.predict(test_embeddings)\n",
    "rl_test_pred = rl_model.predict(test_embeddings)\n",
    "\n",
    "# 确保所有预测结果具有相同长度\n",
    "cnn_train_pred = cnn_train_pred[:len(train_labels)]\n",
    "svm_train_pred = svm_train_pred[:len(train_labels)]\n",
    "rl_train_pred = rl_train_pred[:len(train_labels)]\n",
    "\n",
    "cnn_test_pred = cnn_test_pred[:len(test_labels)]\n",
    "svm_test_pred = svm_test_pred[:len(test_labels)]\n",
    "rl_test_pred = rl_test_pred[:len(test_labels)]\n",
    "\n",
    "# 将每个模型的预测结果作为新的特征\n",
    "stacked_train_features = np.vstack((cnn_train_pred, svm_train_pred, rl_train_pred)).T\n",
    "stacked_test_features = np.vstack((cnn_test_pred, svm_test_pred, rl_test_pred)).T\n",
    "\n",
    "# 创建 VotingClassifier 模型\n",
    "voting_model = VotingClassifier(estimators=[\n",
    "    ('svm', svm_model),\n",
    "    ('rl', rl_model)\n",
    "], voting='soft')\n",
    "\n",
    "# 使用 VotingClassifier 和 CNN 的结果进行堆叠\n",
    "stacking_estimators = [\n",
    "    ('voting', voting_model),\n",
    "    ('cnn', LogisticRegression().fit(stacked_train_features, train_labels))  # 使用 CNN 特征训练逻辑回归\n",
    "]\n",
    "\n",
    "# 创建 StackingClassifier 模型\n",
    "stacking_model = StackingClassifier(estimators=stacking_estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "# 训练 StackingClassifier\n",
    "stacking_model.fit(stacked_train_features, train_labels)\n",
    "\n",
    "# 对测试集进行预测\n",
    "stacked_pred = stacking_model.predict_proba(stacked_test_features)[:, 1]\n",
    "\n",
    "# 将预测结果转换为二分类（例如，0.5 为阈值）\n",
    "stacked_binary_preds = (stacked_pred > 0.5).astype(int)\n",
    "\n",
    "# 计算评估指标\n",
    "conf_matrix = confusion_matrix(test_labels, stacked_binary_preds)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "auc = roc_auc_score(test_labels, stacked_pred)\n",
    "balanced_acc = balanced_accuracy_score(test_labels, stacked_binary_preds)\n",
    "sensitivity = recall_score(test_labels, stacked_binary_preds)\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "mcc = matthews_corrcoef(test_labels, stacked_binary_preds)\n",
    "\n",
    "# 打印评估指标\n",
    "print(f'Balanced Accuracy (BAcc): {balanced_acc:.4f}, Sensitivity (Sn): {sensitivity:.4f}, '\n",
    "      f'Specificity (Sp): {specificity:.4f}, MCC: {mcc:.4f}, AUROC: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy (BAcc): 0.9007, Sensitivity (Sn): 0.9280, Specificity (Sp): 0.8734, MCC: 0.8033, AUROC: 0.9608\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, roc_auc_score, balanced_accuracy_score, recall_score\n",
    "\n",
    "# 加载保存的模型\n",
    "svm_model = joblib.load('/root/ACE/model/best_svm_model.pkl')\n",
    "rl_model = joblib.load('/root/ACE/model/best_logistic_regression_model.pkl')\n",
    "mlp_model = torch.load('/root/ACE/model/best_mlp_model_entire.pth')\n",
    "\n",
    "# 读取训练集和测试集 CSV 文件\n",
    "train_csv_file_path = '/root/ACE/pca_train.csv'\n",
    "test_csv_file_path = '/root/ACE/pca_test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_csv_file_path)\n",
    "test_data = pd.read_csv(test_csv_file_path)\n",
    "\n",
    "# 假设第一列是标签，后面的列都是特征\n",
    "train_labels = train_data.iloc[:, 0]\n",
    "train_embeddings = train_data.iloc[:, 1:]\n",
    "\n",
    "test_labels = test_data.iloc[:, 0]\n",
    "test_embeddings = test_data.iloc[:, 1:]\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(CustomDataset(train_embeddings, train_labels), batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(CustomDataset(test_embeddings, test_labels), batch_size=256, shuffle=False)\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 加载 CNN 模型\n",
    "cnn_model = torch.load('/root/ACE/model/best_model_trial_cnn.pth').to(device)\n",
    "cnn_model.eval()\n",
    "\n",
    "# Define the prediction function\n",
    "def predict_with_torch_model(model, data, device, unsqueeze=False):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data_tensor = torch.tensor(data.values, dtype=torch.float32).to(device)\n",
    "        if unsqueeze:\n",
    "            data_tensor = data_tensor.unsqueeze(1)  # Add an extra dimension for seq_length\n",
    "        outputs = model(data_tensor)\n",
    "        if outputs.size(1) == 1:\n",
    "            # For models with single output (e.g., MLP)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "        else:\n",
    "            # For models with multi-class outputs (e.g., CNN)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
    "    return probs\n",
    "\n",
    "# Use the updated function\n",
    "cnn_train_pred = predict_with_torch_model(cnn_model, train_embeddings, device, unsqueeze=True)\n",
    "cnn_test_pred = predict_with_torch_model(cnn_model, test_embeddings, device, unsqueeze=True)\n",
    "\n",
    "mlp_train_pred = predict_with_torch_model(mlp_model, train_embeddings, device, unsqueeze=False)\n",
    "mlp_test_pred = predict_with_torch_model(mlp_model, test_embeddings, device, unsqueeze=False)\n",
    "\n",
    "\n",
    "# 计算 SVM 和逻辑回归的预测概率\n",
    "svm_train_pred = svm_model.predict_proba(train_embeddings)[:, 1]\n",
    "svm_test_pred = svm_model.predict_proba(test_embeddings)[:, 1]\n",
    "\n",
    "rl_train_pred = rl_model.predict_proba(train_embeddings)[:, 1]\n",
    "rl_test_pred = rl_model.predict_proba(test_embeddings)[:, 1]\n",
    "\n",
    "# 将每个模型的预测结果作为新的特征\n",
    "stacked_train_features = np.vstack((cnn_train_pred, svm_train_pred, rl_train_pred, mlp_train_pred)).T\n",
    "stacked_test_features = np.vstack((cnn_test_pred, svm_test_pred, rl_test_pred, mlp_test_pred)).T\n",
    "\n",
    "# 创建 VotingClassifier 模型\n",
    "voting_model = VotingClassifier(estimators=[\n",
    "    ('svm', svm_model),\n",
    "    ('rl', rl_model),\n",
    "    ('mlp', LogisticRegression().fit(stacked_train_features[:, 3].reshape(-1, 1), train_labels))\n",
    "], voting='soft')\n",
    "\n",
    "# 使用 VotingClassifier 和 CNN、MLP 的结果进行堆叠\n",
    "stacking_estimators = [\n",
    "    ('voting', voting_model),\n",
    "    ('cnn', LogisticRegression().fit(stacked_train_features[:, 0].reshape(-1, 1), train_labels))\n",
    "]\n",
    "\n",
    "# 创建 StackingClassifier 模型\n",
    "stacking_model = StackingClassifier(estimators=stacking_estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "# 训练 StackingClassifier\n",
    "stacking_model.fit(stacked_train_features, train_labels)\n",
    "\n",
    "# 对测试集进行预测\n",
    "stacked_pred = stacking_model.predict_proba(stacked_test_features)[:, 1]\n",
    "stacked_binary_preds = (stacked_pred > 0.5).astype(int)\n",
    "\n",
    "# 计算评估指标\n",
    "auc = roc_auc_score(test_labels, stacked_pred)\n",
    "balanced_acc = balanced_accuracy_score(test_labels, stacked_binary_preds)\n",
    "sensitivity = recall_score(test_labels, stacked_binary_preds)\n",
    "specificity = recall_score(test_labels, stacked_binary_preds, pos_label=0)\n",
    "mcc = matthews_corrcoef(test_labels, stacked_binary_preds)\n",
    "\n",
    "# 打印评估指标\n",
    "print(f'Balanced Accuracy (BAcc): {balanced_acc:.4f}, Sensitivity (Sn): {sensitivity:.4f}, '\n",
    "      f'Specificity (Sp): {specificity:.4f}, MCC: {mcc:.4f}, AUROC: {auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy (BAcc): 0.8927, Sensitivity (Sn): 0.9120, Specificity (Sp): 0.8734, MCC: 0.7836, AUROC: 0.9597\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_csv_file_path = '/root/ACE/pca_train.csv'\n",
    "test_csv_file_path = '/root/ACE/pca_test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_csv_file_path)\n",
    "test_data = pd.read_csv(test_csv_file_path)\n",
    "\n",
    "# Assume the first column is labels, the rest are features\n",
    "train_labels = train_data.iloc[:, 0]\n",
    "train_embeddings = train_data.iloc[:, 1:]\n",
    "\n",
    "test_labels = test_data.iloc[:, 0]\n",
    "test_embeddings = test_data.iloc[:, 1:]\n",
    "\n",
    "# Create datasets and dataloaders (not strictly necessary here but included for completeness)\n",
    "train_dataset = CustomDataset(train_embeddings, train_labels)\n",
    "test_dataset = CustomDataset(test_embeddings, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load saved models\n",
    "svm_model = joblib.load('/root/ACE/model/best_svm_model.pkl')\n",
    "rl_model = joblib.load('/root/ACE/model/best_logistic_regression_model.pkl')\n",
    "mlp_model = torch.load('/root/ACE/model/best_mlp_model_entire.pth', map_location=device)\n",
    "cnn_model = torch.load('/root/ACE/model/best_model_trial_cnn.pth', map_location=device)\n",
    "\n",
    "# Define a wrapper class to integrate PyTorch models with scikit-learn\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class PyTorchClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model, device, unsqueeze=False):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.unsqueeze = unsqueeze\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Assuming the model is already trained\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return (probs[:, 1] > 0.5).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Convert X to tensor if it's not already\n",
    "            if isinstance(X, pd.DataFrame) or isinstance(X, pd.Series):\n",
    "                X = X.values\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "            if self.unsqueeze:\n",
    "                X_tensor = X_tensor.unsqueeze(1)\n",
    "            outputs = self.model(X_tensor)\n",
    "            if outputs.size(1) == 1:\n",
    "                probs_pos = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "                probs_neg = 1 - probs_pos\n",
    "                probs = np.vstack((probs_neg, probs_pos)).T\n",
    "            else:\n",
    "                probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "        return probs\n",
    "\n",
    "# Create instances of the wrapped PyTorch models\n",
    "cnn_wrapper = PyTorchClassifier(cnn_model, device, unsqueeze=True)\n",
    "mlp_wrapper = PyTorchClassifier(mlp_model, device, unsqueeze=False)\n",
    "\n",
    "# Create VotingClassifier with the four models\n",
    "voting_model = VotingClassifier(estimators=[\n",
    "    ('svm', svm_model),\n",
    "    ('rl', rl_model),\n",
    "    ('cnn', cnn_wrapper),\n",
    "    ('mlp', mlp_wrapper)\n",
    "], voting='soft')\n",
    "\n",
    "# Fit the voting model on the training data\n",
    "voting_model.fit(train_embeddings, train_labels)\n",
    "\n",
    "# Predict on the test data\n",
    "stacked_pred = voting_model.predict_proba(test_embeddings)[:, 1]\n",
    "stacked_binary_preds = (stacked_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "auc = roc_auc_score(test_labels, stacked_pred)\n",
    "balanced_acc = balanced_accuracy_score(test_labels, stacked_binary_preds)\n",
    "sensitivity = recall_score(test_labels, stacked_binary_preds)\n",
    "specificity = recall_score(test_labels, stacked_binary_preds, pos_label=0)\n",
    "mcc = matthews_corrcoef(test_labels, stacked_binary_preds)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Balanced Accuracy (BAcc): {balanced_acc:.4f}, Sensitivity (Sn): {sensitivity:.4f}, '\n",
    "      f'Specificity (Sp): {specificity:.4f}, MCC: {mcc:.4f}, AUROC: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy (BAcc): 0.9070, Sensitivity (Sn): 0.9280, Specificity (Sp): 0.8861, MCC: 0.8141, AUROC: 0.9595\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, matthews_corrcoef, roc_auc_score,\n",
    "    balanced_accuracy_score, recall_score\n",
    ")\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Load saved models\n",
    "svm_model = joblib.load('/root/ACE/model/best_svm_model.pkl')\n",
    "rl_model = joblib.load('/root/ACE/model/best_logistic_regression_model.pkl')\n",
    "mlp_model = torch.load('/root/ACE/model/best_mlp_model_entire.pth', map_location='cpu')\n",
    "cnn_model = torch.load('/root/ACE/model/best_model_trial_cnn.pth', map_location='cpu')\n",
    "\n",
    "# Read CSV files\n",
    "train_csv_file_path = '/root/ACE/pca_train.csv'\n",
    "test_csv_file_path = '/root/ACE/pca_test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_csv_file_path)\n",
    "test_data = pd.read_csv(test_csv_file_path)\n",
    "\n",
    "# Assume first column is labels, rest are features\n",
    "train_labels = train_data.iloc[:, 0]\n",
    "train_embeddings = train_data.iloc[:, 1:]\n",
    "\n",
    "test_labels = test_data.iloc[:, 0]\n",
    "test_embeddings = test_data.iloc[:, 1:]\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define PyTorchClassifier class\n",
    "class PyTorchClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model, device, unsqueeze=False):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.unsqueeze = unsqueeze\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        # Since the model is already trained, we don't need to do anything else\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X = X.values\n",
    "            data_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "            if self.unsqueeze:\n",
    "                data_tensor = data_tensor.unsqueeze(1)\n",
    "            outputs = self.model(data_tensor)\n",
    "            if outputs.size(1) == 1:\n",
    "                probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "                # Ensure columns correspond to self.classes_\n",
    "                probs = np.hstack([1 - probs, probs])\n",
    "            else:\n",
    "                probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        class_index = np.argmax(probs, axis=1)\n",
    "        return self.classes_[class_index]\n",
    "\n",
    "# Wrap the PyTorch models\n",
    "mlp_estimator = PyTorchClassifier(mlp_model, device=device, unsqueeze=False)\n",
    "cnn_estimator = PyTorchClassifier(cnn_model, device=device, unsqueeze=True)\n",
    "\n",
    "# Fit the estimators (to set classes_)\n",
    "mlp_estimator.fit(train_embeddings, train_labels)\n",
    "cnn_estimator.fit(train_embeddings, train_labels)\n",
    "\n",
    "# Collect predictions from base estimators\n",
    "svm_train_pred = svm_model.predict_proba(train_embeddings)[:, 1]\n",
    "svm_test_pred = svm_model.predict_proba(test_embeddings)[:, 1]\n",
    "\n",
    "rl_train_pred = rl_model.predict_proba(train_embeddings)[:, 1]\n",
    "rl_test_pred = rl_model.predict_proba(test_embeddings)[:, 1]\n",
    "\n",
    "mlp_train_pred = mlp_estimator.predict_proba(train_embeddings)[:, 1]\n",
    "mlp_test_pred = mlp_estimator.predict_proba(test_embeddings)[:, 1]\n",
    "\n",
    "cnn_train_pred = cnn_estimator.predict_proba(train_embeddings)[:, 1]\n",
    "cnn_test_pred = cnn_estimator.predict_proba(test_embeddings)[:, 1]\n",
    "\n",
    "# Stack predictions as new features\n",
    "stacked_train_features = np.vstack((\n",
    "    svm_train_pred,\n",
    "    rl_train_pred,\n",
    "    mlp_train_pred,\n",
    "    cnn_train_pred\n",
    ")).T\n",
    "\n",
    "stacked_test_features = np.vstack((\n",
    "    svm_test_pred,\n",
    "    rl_test_pred,\n",
    "    mlp_test_pred,\n",
    "    cnn_test_pred\n",
    ")).T\n",
    "\n",
    "\n",
    "C = 1e3\n",
    "solver = 'saga'\n",
    "penalty = 'l1'\n",
    "tol = 1e-4\n",
    "max_iter = 3000\n",
    "    \n",
    "\n",
    "# Train final estimator\n",
    "final_estimator = LogisticRegression(C=C, solver=solver, penalty=penalty, tol=tol, max_iter=max_iter)\n",
    "final_estimator.fit(stacked_train_features, train_labels)\n",
    "\n",
    "# Evaluate on test set\n",
    "stacked_pred = final_estimator.predict_proba(stacked_test_features)[:, 1]\n",
    "stacked_binary_preds = (stacked_pred > 0.5).astype(int)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "auc = roc_auc_score(test_labels, stacked_pred)\n",
    "balanced_acc = balanced_accuracy_score(test_labels, stacked_binary_preds)\n",
    "sensitivity = recall_score(test_labels, stacked_binary_preds)\n",
    "specificity = recall_score(test_labels, stacked_binary_preds, pos_label=0)\n",
    "mcc = matthews_corrcoef(test_labels, stacked_binary_preds)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Balanced Accuracy (BAcc): {balanced_acc:.4f}, Sensitivity (Sn): {sensitivity:.4f}, '\n",
    "      f'Specificity (Sp): {specificity:.4f}, MCC: {mcc:.4f}, AUROC: {auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy (BAcc): 0.9007, Sensitivity (Sn): 0.9280, Specificity (Sp): 0.8734, MCC: 0.8033, AUROC: 0.9600\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, matthews_corrcoef, roc_auc_score,\n",
    "    balanced_accuracy_score, recall_score\n",
    ")\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from itertools import combinations\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Load saved models\n",
    "svm_model = joblib.load('/root/ACE/model/best_svm_model.pkl')\n",
    "rl_model = joblib.load('/root/ACE/model/best_logistic_regression_model.pkl')\n",
    "mlp_model = torch.load('/root/ACE/model/best_mlp_model_entire.pth', map_location='cpu')\n",
    "cnn_model = torch.load('/root/ACE/model/best_model_trial_cnn.pth', map_location='cpu')\n",
    "\n",
    "# Read CSV files\n",
    "train_csv_file_path = '/root/ACE/pca_train.csv'\n",
    "test_csv_file_path = '/root/ACE/pca_test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_csv_file_path)\n",
    "test_data = pd.read_csv(test_csv_file_path)\n",
    "\n",
    "# Assume first column is labels, rest are features\n",
    "train_labels = train_data.iloc[:, 0]\n",
    "train_embeddings = train_data.iloc[:, 1:]\n",
    "\n",
    "test_labels = test_data.iloc[:, 0]\n",
    "test_embeddings = test_data.iloc[:, 1:]\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define PyTorchClassifier class\n",
    "class PyTorchClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model, device, unsqueeze=False):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.unsqueeze = unsqueeze\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        # Since the model is already trained, we don't need to do anything else\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X = X.values\n",
    "            data_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "            if self.unsqueeze:\n",
    "                data_tensor = data_tensor.unsqueeze(1)\n",
    "            outputs = self.model(data_tensor)\n",
    "            if outputs.size(1) == 1:\n",
    "                probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "                probs = np.hstack([1 - probs, probs])\n",
    "            else:\n",
    "                probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        class_index = np.argmax(probs, axis=1)\n",
    "        return self.classes_[class_index]\n",
    "\n",
    "# Wrap the PyTorch models\n",
    "mlp_estimator = PyTorchClassifier(mlp_model, device=device, unsqueeze=False)\n",
    "cnn_estimator = PyTorchClassifier(cnn_model, device=device, unsqueeze=True)\n",
    "\n",
    "# Fit the estimators (to set classes_)\n",
    "mlp_estimator.fit(train_embeddings, train_labels)\n",
    "cnn_estimator.fit(train_embeddings, train_labels)\n",
    "\n",
    "# Define all estimators\n",
    "all_estimators = [('svm', svm_model), ('rl', rl_model), ('mlp', mlp_estimator), ('cnn', cnn_estimator)]\n",
    "\n",
    "# Create combinations of three estimators for voting\n",
    "voting_models = []\n",
    "for combo in combinations(all_estimators, 3):\n",
    "    voting_clf = VotingClassifier(estimators=list(combo), voting='soft')\n",
    "    voting_clf.fit(train_embeddings, train_labels)\n",
    "    voting_models.append(voting_clf)\n",
    "\n",
    "# Collect predictions from each voting model for stacking\n",
    "train_preds = []\n",
    "test_preds = []\n",
    "\n",
    "for voting_clf in voting_models:\n",
    "    train_pred = voting_clf.predict_proba(train_embeddings)[:, 1]\n",
    "    test_pred = voting_clf.predict_proba(test_embeddings)[:, 1]\n",
    "    train_preds.append(train_pred)\n",
    "    test_preds.append(test_pred)\n",
    "\n",
    "# Stack the voting model predictions as new features\n",
    "stacked_train_features = np.vstack(train_preds).T\n",
    "stacked_test_features = np.vstack(test_preds).T\n",
    "\n",
    "# Train final estimator using the stacked features\n",
    "C = 1e3\n",
    "solver = 'saga'\n",
    "penalty = 'l1'\n",
    "tol = 1e-4\n",
    "max_iter = 3000\n",
    "\n",
    "final_estimator = LogisticRegression(max_iter=max_iter)\n",
    "final_estimator.fit(stacked_train_features, train_labels)\n",
    "\n",
    "# Evaluate on test set\n",
    "stacked_pred = final_estimator.predict_proba(stacked_test_features)[:, 1]\n",
    "stacked_binary_preds = (stacked_pred > 0.5).astype(int)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "auc = roc_auc_score(test_labels, stacked_pred)\n",
    "balanced_acc = balanced_accuracy_score(test_labels, stacked_binary_preds)\n",
    "sensitivity = recall_score(test_labels, stacked_binary_preds)\n",
    "specificity = recall_score(test_labels, stacked_binary_preds, pos_label=0)\n",
    "mcc = matthews_corrcoef(test_labels, stacked_binary_preds)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Balanced Accuracy (BAcc): {balanced_acc:.4f}, Sensitivity (Sn): {sensitivity:.4f}, '\n",
    "      f'Specificity (Sp): {specificity:.4f}, MCC: {mcc:.4f}, AUROC: {auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy (BAcc): 0.9110, Sensitivity (Sn): 0.9360, Specificity (Sp): 0.8861, MCC: 0.8240, AUROC: 0.9615\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, matthews_corrcoef, roc_auc_score,\n",
    "    balanced_accuracy_score, recall_score\n",
    ")\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Load saved models\n",
    "svm_model = joblib.load('/root/ACE/model/best_svm_model.pkl')\n",
    "rl_model = joblib.load('/root/ACE/model/best_logistic_regression_model.pkl')\n",
    "mlp_model = torch.load('/root/ACE/model/best_mlp_model_entire.pth', map_location='cpu')\n",
    "cnn_model = torch.load('/root/ACE/model/best_model_trial_cnn.pth', map_location='cpu')\n",
    "\n",
    "# Read CSV files\n",
    "train_csv_file_path = '/root/ACE/pca_train.csv'\n",
    "test_csv_file_path = '/root/ACE/pca_test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_csv_file_path)\n",
    "test_data = pd.read_csv(test_csv_file_path)\n",
    "\n",
    "# Assume first column is labels, rest are features\n",
    "train_labels = train_data.iloc[:, 0]\n",
    "train_embeddings = train_data.iloc[:, 1:]\n",
    "\n",
    "test_labels = test_data.iloc[:, 0]\n",
    "test_embeddings = test_data.iloc[:, 1:]\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define PyTorchClassifier class\n",
    "class PyTorchClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model, device, unsqueeze=False):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.unsqueeze = unsqueeze\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X = X.values\n",
    "            data_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "            if self.unsqueeze:\n",
    "                data_tensor = data_tensor.unsqueeze(1)\n",
    "            outputs = self.model(data_tensor)\n",
    "            if outputs.size(1) == 1:\n",
    "                probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "                probs = np.hstack([1 - probs, probs])\n",
    "            else:\n",
    "                probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "        return probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        class_index = np.argmax(probs, axis=1)\n",
    "        return self.classes_[class_index]\n",
    "\n",
    "# Wrap the PyTorch models\n",
    "mlp_estimator = PyTorchClassifier(mlp_model, device=device, unsqueeze=False)\n",
    "cnn_estimator = PyTorchClassifier(cnn_model, device=device, unsqueeze=True)\n",
    "\n",
    "# Fit the estimators to set classes_\n",
    "mlp_estimator.fit(train_embeddings, train_labels)\n",
    "cnn_estimator.fit(train_embeddings, train_labels)\n",
    "\n",
    "# Define Voting for svm+cnn\n",
    "voting1 = VotingClassifier(estimators=[\n",
    "    ('svm', svm_model),\n",
    "    ('cnn', cnn_estimator)\n",
    "], voting='soft')\n",
    "\n",
    "# Define Voting for mlp+rl\n",
    "voting2 = VotingClassifier(estimators=[\n",
    "    ('mlp', mlp_estimator),\n",
    "    ('rl', rl_model)\n",
    "], voting='soft')\n",
    "\n",
    "# Fit Voting models\n",
    "voting1.fit(train_embeddings, train_labels)\n",
    "voting2.fit(train_embeddings, train_labels)\n",
    "\n",
    "# Get predictions from Voting classifiers\n",
    "voting1_train_pred = voting1.predict_proba(train_embeddings)[:, 1]\n",
    "voting1_test_pred = voting1.predict_proba(test_embeddings)[:, 1]\n",
    "\n",
    "voting2_train_pred = voting2.predict_proba(train_embeddings)[:, 1]\n",
    "voting2_test_pred = voting2.predict_proba(test_embeddings)[:, 1]\n",
    "\n",
    "# Stack predictions as new features\n",
    "stacked_train_features = np.vstack((voting1_train_pred, voting2_train_pred)).T\n",
    "stacked_test_features = np.vstack((voting1_test_pred, voting2_test_pred)).T\n",
    "\n",
    "# Define hyperparameters for final estimator\n",
    "C = 1e3\n",
    "solver = 'saga'\n",
    "penalty = 'l1'\n",
    "tol = 1e-4\n",
    "max_iter = 3000\n",
    "\n",
    "# Train final estimator (Logistic Regression)\n",
    "final_estimator = LogisticRegression(C=C, solver=solver, penalty=penalty, tol=tol, max_iter=max_iter)\n",
    "final_estimator.fit(stacked_train_features, train_labels)\n",
    "\n",
    "# Evaluate on test set\n",
    "stacked_pred = final_estimator.predict_proba(stacked_test_features)[:, 1]\n",
    "stacked_binary_preds = (stacked_pred > 0.5).astype(int)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "auc = roc_auc_score(test_labels, stacked_pred)\n",
    "balanced_acc = balanced_accuracy_score(test_labels, stacked_binary_preds)\n",
    "sensitivity = recall_score(test_labels, stacked_binary_preds)\n",
    "specificity = recall_score(test_labels, stacked_binary_preds, pos_label=0)\n",
    "mcc = matthews_corrcoef(test_labels, stacked_binary_preds)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Balanced Accuracy (BAcc): {balanced_acc:.4f}, Sensitivity (Sn): {sensitivity:.4f}, '\n",
    "      f'Specificity (Sp): {specificity:.4f}, MCC: {mcc:.4f}, AUROC: {auc:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "po",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
